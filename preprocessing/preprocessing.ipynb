{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9138c585-ceec-4806-aeae-e9c9535973f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59d4507-00e4-4cd5-b365-a5f9e19a75b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants :\n",
    "\n",
    "propertyMapper = {\n",
    "    'township': {\n",
    "        'unknown': 'Inconnue',\n",
    "        'paris01': 'PARIS 01',\n",
    "        'paris02': 'PARIS 02',\n",
    "        'paris03': 'PARIS 03',\n",
    "        'paris04': 'PARIS 04',\n",
    "        'paris05': 'PARIS 05',\n",
    "        'paris06': 'PARIS 06',\n",
    "        'paris07': 'PARIS 07',\n",
    "        'paris08': 'PARIS 08',\n",
    "        'paris09': 'PARIS 09',\n",
    "        'paris10': 'PARIS 10',\n",
    "        'paris11': 'PARIS 11',\n",
    "        'paris12': 'PARIS 12',\n",
    "        'paris13': 'PARIS 13',\n",
    "        'paris14': 'PARIS 14',\n",
    "        'paris15': 'PARIS 15',\n",
    "        'paris16': 'PARIS 16',\n",
    "        'paris17': 'PARIS 17',\n",
    "        'paris18': 'PARIS 18',\n",
    "        'paris19': 'PARIS 19',\n",
    "        'paris20': 'PARIS 20',\n",
    "        'val_de_marne': 'Val-de-Marne',\n",
    "        'yvelines': 'Yvelines',\n",
    "        'seine_et_marne': 'Seine-et-Marne',\n",
    "        'val_d_oise': \"Val d'Oise\",\n",
    "        'hauts_de_seine': 'Hauts-de-Seine',\n",
    "        'essonne': 'Essonne',\n",
    "        'seine_saint_denis': \"Seine-Saint-Denis\"\n",
    "    },\n",
    "    'year': {\n",
    "        '2013': '2013',\n",
    "        '2014': '2014',\n",
    "        '2015': '2015',\n",
    "        '2016': '2016',\n",
    "        '2017': '2017',\n",
    "        '2018': '2018',\n",
    "        '2019': '2019',\n",
    "        '2020': '2020',\n",
    "        '2021': '2021',\n",
    "        '2022': '2022',\n",
    "        '2023': '2023',\n",
    "    },\n",
    "    'city_committee': {\n",
    "        'DDCT': 'DDCT', 'DAC': 'DAC', 'DJS': 'DJS', 'DASES': 'DASES', 'DAE': 'DAE', 'DFPE': 'DFPE', 'DASCO': 'DASCO', 'DPSP': 'DPSP', 'DPVI': 'DPVI',\n",
    "        'DGRI': 'DGRI', 'DEVE': 'DEVE', 'DSOL': 'DSOL', 'DPMP': 'DPMP', 'DPE': 'DPE', 'DSP': 'DSP', 'DVD': 'DVD', 'SG': 'SG', 'DUCT': 'DUCT',\n",
    "        'DGOM': 'DGOM', 'DLH': 'DLH', 'SG-MI-CINEMA': 'SG-MI-CINEMA', 'DU': 'DU', 'DTEC': 'DTEC', 'DRH': 'DRH', 'DFA': 'DFA', 'DICOM': 'DICOM',\n",
    "        'CASVP': 'CASVP', 'DAJ': 'DAJ', 'DILT': 'DILT', 'SG-DPMC': 'SG-DPMC', 'SGCP': 'SGCP'\n",
    "    },\n",
    "    'activity': {\n",
    "        'culture_arts': 'Culture & Arts', 'education_formation': 'Education & formation',\n",
    "        'rights_interests_defense': 'Défense des droits et des intérêts', 'hobbies': 'Loisirs', 'social': 'Social',\n",
    "        'precarity_exclusion': 'Précarité & Exclusion', 'association_help': 'Aides aux associations', 'sport': 'Sport', 'work': 'Emploi',\n",
    "        'communication_media': 'Communication & média', 'humanitarian': 'Humanitaire', 'economy': 'Economie',\n",
    "        'environment_ecology': 'Environnement & écologie', 'health': 'Santé', 'local_life': 'Vie et animation locale',\n",
    "        'architecture_urban_planning': 'Architecture & urbanisme', 'memory': 'Mémoire', 'travel_means': 'Déplacements et transports',\n",
    "        'international_relationships': 'Relations internationales', 'ideas_opinions': 'Idée & opinion', 'tourism': 'Tourisme',\n",
    "        'technology_research': 'Technique & Recherche'\n",
    "    },\n",
    "    'aim_subvention': {\n",
    "        'not_specified': 'Non précisée', 'project': 'Projet', 'operation': 'Fonctionnement', 'investment': 'Investissement'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc62e26-050b-4af6-8aa6-61fdc3d4e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions :\n",
    "\n",
    "        # Creating a new file with selected columns streaming from a file via a file descriptor :\n",
    "\n",
    "def createFileWithSpecificColumns(origin, destination):\n",
    "    with open(origin) as b, open(destination,'w', encoding = 'utf-8') as e:\n",
    "        line = b.readline()\n",
    "        while line!='':\n",
    "            splittedLine = line.split(',')\n",
    "            siret = splittedLine[2]\n",
    "            postalCode = splittedLine[16]\n",
    "            e.write(f'{siret},{postalCode}' +\"\\n\")\n",
    "            line = b.readline()\n",
    "\n",
    "        # Checking data validity :\n",
    "\n",
    "def checkFalseDuplicates(x, year):\n",
    "    data_tmp = x[x['Année budgétaire'] == year]\n",
    "    \n",
    "    def check(row):\n",
    "        file_id=row['Numéro de dossier']\n",
    "        same_file_id_row_amount = data_tmp[data_tmp['Numéro de dossier'] == file_id]['Montant voté']\n",
    "        result = (same_file_id_row_amount == row['Montant voté']).value_counts()\n",
    "        if False in result.index:\n",
    "            return False\n",
    "        else :\n",
    "            return True\n",
    "    return data_tmp.apply(check, axis=1)\n",
    "\n",
    "        # Transforming data types :\n",
    "\n",
    "def transformOriginDataTypesIntoFinalDataTypes(dataset, originDTypes, finalDTypes):\n",
    "    for (originDType, finalDType) in zip(originDTypes, finalDTypes):\n",
    "        for column in dataset.dtypes[dataset.dtypes == originDType].index:\n",
    "            dataset[column] = dataset[column].astype(finalDType)\n",
    "    return dataset\n",
    "\n",
    "def transformSelectedColumnsDataTypeIntoSpecifiedDataType(dataset, columnsDataTypeMapping):\n",
    "    for column, dtype in columnsDataTypeMapping.items():\n",
    "        dataset[column] = dataset[column].astype(dtype)\n",
    "    return dataset\n",
    "    \n",
    "        #Selecting (or filtering) data:\n",
    "\n",
    "def selectingRowsWithSpecificValuesInSpecifiedColumn(dataset, column, values):\n",
    "    if (not isinstance(values,list)):\n",
    "        return (dataset[column] == values)           \n",
    "    tempMask = (dataset[column] == values[0])\n",
    "    if (len(values) == 1):\n",
    "        return tempMask        \n",
    "    for value in values[1:]:\n",
    "        tempMask |= (dataset[column] == value)        \n",
    "    return tempMask\n",
    "\n",
    "def selectRowsWithSpecificValuesInSpecifiedColumns(dataset,columnsValuesMapping):\n",
    "    if not len(columnsValuesMapping):\n",
    "        return dataset\n",
    "    \n",
    "    columns, values = list(columnsValuesMapping.keys()), list(columnsValuesMapping.values())\n",
    "    mask = selectingRowsWithSpecificValuesInSpecifiedColumn(dataset, columns[0],values[0])\n",
    "    \n",
    "    if (len(columns) == 1):\n",
    "        return dataset[mask]\n",
    "        \n",
    "    for column, selectedValues in zip(columns[1:], values[1:]):\n",
    "        tempMask = selectingRowsWithSpecificValuesInSpecifiedColumn(dataset, column, selectedValues)\n",
    "        mask &= (tempMask)\n",
    "    return dataset[mask]\n",
    "\n",
    "def siretTypeChanger(x):\n",
    "    if x!=x:\n",
    "        return x\n",
    "    if len(x.split(' '))!= 1:\n",
    "        return x\n",
    "    if len(x.split('.'))!= 1:\n",
    "        return int(x.split('.')[0] + x.split('.')[1])\n",
    "    return int(x)\n",
    "    \n",
    "    # Merging postal code informations :\n",
    "\n",
    "def mergePostalCodeValues(x):\n",
    "    postalCodeSiret = x['codePostalEtablissement']\n",
    "    postalCodeAssociation = x['CP-Adresse-Code postal']\n",
    "    if postalCodeSiret == postalCodeSiret:\n",
    "        return postalCodeSiret\n",
    "    return postalCodeAssociation\n",
    "\n",
    "    #Aggregating townships into departments for towns outside of Paris but in the region of IdF :\n",
    "\n",
    "def aggregateTownship(x):\n",
    "    township = x['Nom_de_la_commune']\n",
    "    postal_code = str(x['Code_postal'])\n",
    "    if postal_code.startswith('77'):\n",
    "        township='Seine-et-Marne'\n",
    "    if postal_code.startswith('78'):\n",
    "        township='Yvelines'\n",
    "    if postal_code.startswith('91'):\n",
    "        township='Essonne'\n",
    "    if postal_code.startswith('92'):\n",
    "        township='Hauts-de-Seine'\n",
    "    if postal_code.startswith('93'):\n",
    "        township='Seine-Saint-Denis'\n",
    "    if postal_code.startswith('94'):\n",
    "        township='Val-de-Marne'\n",
    "    if postal_code.startswith('95'):\n",
    "        township=\"Val d'Oise\"\n",
    "    return township\n",
    "\n",
    "\n",
    "    # Creating data objects : \n",
    "\n",
    "def df_to_dict(df, selected_columns):\n",
    "    tmp_df = df[selected_columns]\n",
    "    dict = {}\n",
    "    for idx in range(tmp_df.shape[0]):\n",
    "        dict[idx] = {}\n",
    "        for column in selected_columns:\n",
    "            dict[idx][column]= str(tmp_df.iloc[idx][column])\n",
    "    return dict\n",
    "\n",
    "def mapping_properties(property, property_value):\n",
    "     for key,value in propertyMapper[property].items():\n",
    "         if (property_value == value):\n",
    "             return key\n",
    "\n",
    "def populatingResponse(response, data, properties_order, depth):\n",
    "    property = properties_order[depth]\n",
    "    for property_value in data[property].value_counts().index:\n",
    "        mapped_property_value =mapping_properties(property, property_value)\n",
    "        response[mapped_property_value] = {}\n",
    "        tmp_data = data[data[property] == property_value]\n",
    "        response[mapped_property_value]['total'] = str(tmp_data['subvention_amount'].sum())\n",
    "        if (len(properties_order) == depth + 1):\n",
    "            continue\n",
    "        populatingResponse(response[mapped_property_value], tmp_data, properties_order, depth + 1)\n",
    "\n",
    "def populatingPerAsso(data, selected_columns):\n",
    "    res = []\n",
    "    distinct_val = data['association'].value_counts().index\n",
    "    for asso in distinct_val:\n",
    "        res.append({ 'name': asso, 'subventions': df_to_dict(data[data['association'] == asso],selected_columns)}) \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2a1bd56-e0f8-432e-a649-bbddbe033cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1667M  100 1667M    0     0  14.3M      0  0:01:56  0:01:56 --:--:-- 13.9M349M    0     0  20.5M      0  0:01:20  0:00:16  0:01:04 12.6M 1667M   28  482M    0     0  18.5M      0  0:01:29  0:00:25  0:01:04 13.4M 0  16.2M      0  0:01:42  0:00:37  0:01:05 11.9M   0  0:01:44  0:00:40  0:01:04 13.1M   0  14.3M      0  0:01:56  0:01:55  0:00:01 13.6M\n"
     ]
    }
   ],
   "source": [
    "!curl 'https://files.data.gouv.fr/insee-sirene/StockEtablissement_utf8.zip' > ./data/siret.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88480ef9-530d-40ff-9fa2-43d61fcb19f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./data/siret.zip\n",
      "  inflating: data/StockEtablissement_utf8.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip ./data/siret.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d649b59b-c69e-44d1-b185-bbbc2e014b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Récupération des subventions faites aux associations par la Mairie de Paris :\n",
    "\n",
    "data_subvention_paris_association = pd.read_csv('https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/subventions-accordees-et-refusees/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B', sep=';', low_memory = False)\n",
    "\n",
    "    # Récupération de la liste des associations parisiennes :\n",
    "\n",
    "data_paris_association = pd.read_csv('https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/liste_des_associations_parisiennes/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B', sep=';', low_memory = False)\n",
    "\n",
    "     # Récupération des codes postaux associés au SIRET :\n",
    "\n",
    "createFileWithSpecificColumns('./data/StockEtablissement_utf8.csv', './data/postal_code_siret.csv')\n",
    "\n",
    "data_siret_postal_code = pd.read_csv('./data/postal_code_siret.csv', header = 0, sep = ',')\n",
    "\n",
    "    # Récupération des données relatives aux codes postaux :\n",
    "\n",
    "data_postal_code = pd.read_csv('https://data.iledefrance.fr/api/explore/v2.1/catalog/datasets/base-officielle-des-codes-postaux/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B', header = 0, sep = ';')[['Code_postal','Nom_de_la_commune']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc540d38-7255-489e-9c65-2819bda2bba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data preparation :\n",
    "\n",
    "    # Deleting NaN values :\n",
    "\n",
    "data_subvention_paris_association = data_subvention_paris_association.dropna(subset = ['Montant voté', 'Année budgétaire'])\n",
    "data_paris_association=data_paris_association.dropna(subset = ['CP-Adresse-Code postal'])\n",
    "\n",
    "    # Transforming dtypes :\n",
    "\n",
    "data_subvention_paris_association = transformOriginDataTypesIntoFinalDataTypes(data_subvention_paris_association, ['float64'], ['int'])\n",
    "data_paris_association = transformOriginDataTypesIntoFinalDataTypes(data_paris_association, ['float64'], ['int'])\n",
    "data_subvention_paris_association['Numéro Siret'] = data_subvention_paris_association['Numéro Siret'].apply(siretTypeChanger)\n",
    "data_postal_code = data_postal_code.astype({ 'Code_postal': str})\n",
    "\n",
    "    # Merging datasets :\n",
    "\n",
    "data = pd.merge(data_subvention_paris_association , data_siret_postal_code, how='left', left_on = \"Numéro Siret\", right_on=\"siret\")\n",
    "data = pd.merge(data, data_paris_association, how = 'left', left_on = 'Nom Bénéficiaire', right_on = 'PR-Nom Statutaire')\n",
    "\n",
    "    # Dropping duplicate rows (same file_id) for each year :\n",
    "\n",
    "minYear = data_subvention_paris_association['Année budgétaire'].min().astype(int)\n",
    "maxYear = data_subvention_paris_association['Année budgétaire'].max().astype(int)\n",
    "years = list(range(minYear,maxYear + 1))\n",
    "\n",
    "final_data = data[data['Année budgétaire'] == minYear].drop_duplicates(subset=\"Numéro de dossier\", keep = 'first')\n",
    "\n",
    "for year in years[1:]:\n",
    "    final_data = pd.concat([final_data, data[data['Année budgétaire'] == year].drop_duplicates(subset = \"Numéro de dossier\", keep=\"first\")])\n",
    "\n",
    "    # Merging postal code from siret db and association db :\n",
    "\n",
    "final_data['postal_code'] = final_data.apply(mergePostalCodeValues, axis = 1)\n",
    "\n",
    "    # Mergin township names with the base data :\n",
    "\n",
    "final_data = pd.merge(final_data, data_postal_code, how=\"left\", left_on='postal_code', right_on='Code_postal')\n",
    "\n",
    "    # Aggregating townships into departments for towns outside of Paris but in the region of IdF :\n",
    "\n",
    "final_data['Nom_de_la_commune'] = final_data.apply(aggregateTownship, axis = 1)\n",
    "\n",
    "    # Splitting 'Secteurs d'activités définies par l'association' column into 3 different columns :\n",
    "\n",
    "final_data = pd.concat([final_data, final_data[\"Secteurs d'activités définies par l'association\"].str.split(',', expand = True).rename(columns  = {0: 'activity_1', 1: 'activity_2', 2: 'activity_3'})], axis = 1)\n",
    "    \n",
    "    # Selecting columns :\n",
    "\n",
    "selected_columns = [\"Numéro de dossier\", 'Année budgétaire', 'Nom Bénéficiaire', 'Objet du dossier', 'Montant voté',\n",
    "                    'Direction', 'Nature de la subvention', 'activity_1', 'activity_2','activity_3','Code_postal', 'Nom_de_la_commune']\n",
    "\n",
    "final_data = final_data[selected_columns]\n",
    "\n",
    "    # Renaming Columns :\n",
    "\n",
    "mapping_new_names_columns = { \"Numéro de dossier\": \"file_id\", 'Année budgétaire':'year', 'Nom Bénéficiaire': 'association',\n",
    "                             \"Objet du dossier\": \"file_object\",'Montant voté': 'subvention_amount', 'Direction': 'city_committee', \n",
    "                             \"Nature de la subvention\": \"aim_subvention\", \"Secteurs d'activités définies par l'association\" : \"activities\", \n",
    "                             'Nom_de_la_commune': 'township', 'Code_postal': 'postal_code', 'activity_1': 'activity'}\n",
    "\n",
    "final_data = final_data.rename(columns = mapping_new_names_columns)\n",
    "\n",
    "    # Typing as string :\n",
    "\n",
    "final_data = final_data.astype({'year':str})\n",
    "\n",
    "    # Transforming nan township values into string 'Inconnue':\n",
    "\n",
    "final_data['township'] = final_data['township'].fillna('Inconnue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aeeb7cb-055c-49c5-9a60-26194f074101",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Populating aggregated data object :\n",
    "\n",
    "aggData = {}\n",
    "non_null = final_data[final_data['subvention_amount'] != 0]\n",
    "mask = non_null['postal_code'] != non_null['postal_code']\n",
    "\n",
    "located = non_null[~mask]\n",
    "unknown = non_null[mask]\n",
    "\n",
    "aggData['unknown'] = {}\n",
    "aggData['unknown']['total'] = str(unknown['subvention_amount'].sum())\n",
    "\n",
    "populatingResponse(aggData, located, ['township', 'year','city_committee', 'activity', 'aim_subvention'], 0)\n",
    "populatingResponse(aggData['unknown'], unknown, ['year', 'city_committee', 'activity', 'aim_subvention'], 0)\n",
    "\n",
    "with open('../web/assets/data/data.json', 'w') as f:\n",
    "    f.write(json.dumps(aggData))\n",
    "\n",
    "## Populating data per association object :\n",
    "\n",
    "asso_data = populatingPerAsso(final_data, ['year', 'association', 'subvention_amount', 'city_committee', 'aim_subvention', 'activity', 'township',\"file_id\", \"file_object\"])\n",
    "\n",
    "with open('../web/assets/data/asso_data.json','w') as f :\n",
    "    f.write(json.dumps(asso_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc50f-8843-4000-b301-3646a77888a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
